{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f66db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(rf\"/nfs/home/genovese/thesis-wildfire-genovese/src\")\n",
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "data_folder = \"/nfs/home/genovese/thesis-wildfire-genovese/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "confini = gpd.read_file('/nfs/home/genovese/thesis-wildfire-genovese/data/clean_data/confini_piemonte/confini_piemonte.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = dict()\n",
    "\n",
    "for a in list(range(2000, 2025)):\n",
    "    meteo[a] = gpd.read_file(f'/nfs/home/genovese/thesis-wildfire-genovese/data/gathering_geojson/weather_forecast/{a}.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b902c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_totale = pd.concat(list(meteo.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d5104",
   "metadata": {},
   "source": [
    "## Ordinary Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58cf4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrige.ok import OrdinaryKriging\n",
    "\n",
    "gdf = meteo[2000]\n",
    "\n",
    "mask = gdf['tmedia'].dropna().index \n",
    "day = gdf.loc[mask, :][gdf.loc[mask, :].data == '2000-01-03'].to_crs(epsg=4326)\n",
    "\n",
    "# 5. Extract lat, lon, and temperature data\n",
    "lons = day.geometry.x.values\n",
    "lats = day.geometry.y.values\n",
    "temps = day['tmedia'].values\n",
    "\n",
    "# 6. Interpolate using kriging from LandSklim\n",
    "result = OrdinaryKriging(lons, lats, temps, verbose=True, variogram_model='gaussian')\n",
    "\n",
    "grid_lons = np.linspace(confini.total_bounds[0], confini.total_bounds[2], 1000)\n",
    "grid_lats = np.linspace(confini.total_bounds[1], confini.total_bounds[3], 1000)\n",
   "\n",
    "z, ss = result.execute('grid', grid_lons, grid_lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "plt.pcolormesh(grid_lons, grid_lats, z)\n",
    "# confini.plot(ax=ax, color='lightgray', alpha=0.5)\n",
    "plt.scatter(lons, lats, c=temps, edgecolors='k', marker='o', label='Data points')\n",
    "\n",
    "plt.colorbar(label='Predicted Value')\n",
    "plt.title('Kriging Interpolation')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import itertools\n",
    "\n",
    "# Define variogram models for the grid search\n",
    "variogram_models = {'hole-effect', 'spherical', 'exponential', 'gaussian', 'linear', 'power'}\n",
    "ranges = [10, 20, 30]\n",
    "slopes = [0.1, 0.3, 0.5]\n",
    "sills = [1, 5, 7]\n",
    "nuggets = [0, 2, 5]\n",
    "scales = [1,3,5]\n",
    "exponent = [1,2,3]\n",
    "\n",
    "\n",
    "# Grid search to find the best variogram parameters\n",
    "best_model = None\n",
    "best_rmse = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for var_model, slope_val, range_val, sill_val, nugget_val, scale_val, exponent_val in list(itertools.product(variogram_models, ranges, slopes, sills, nuggets
, scales, exponent)):\n",
    "                    # Create an OrdinaryKriging object\n",
    "                    OK = OrdinaryKriging(lons, lats, temps, variogram_model=var_model, \n",
    "                                     variogram_parameters={\n",
    "                                             'slope': slope_val, \n",
    "                                             'range': range_val, \n",
    "                                             'sill': sill_val, \n",
    "                                             'nugget': nugget_val,\n",
    "                                             'scale': scale_val,\n",
    "                                             'exponent': exponent_val},\n",
    "                                     verbose=False, enable_plotting=False)\n",
    "                \n",
    "                    z_pred, ss = result.execute('points', lons, lats)\n",
    "\n",
    "                    rmse = np.sqrt(mean_squared_error(temps, z_pred.flatten()))\n",
    "                \n",
    "                    # print(f\"Model: {var_model}, Range: {range_val}, Sill: {sill_val}, Nugget: {nugget_val}, RMSE: {rmse}\")\n",
    "\n",
    "                    # Update best model if current RMSE is better\n",
    "                    if rmse < best_rmse:\n",
    "                        best_rmse = rmse\n",
    "                        best_model = var_model\n",
    "                        best_params = (range_val, sill_val, nugget_val)\n",
    "\n",
    "# Output the best model and parameters\n",
    "print(\"\\nBest Model:\", best_model)\n",
    "print(\"Best Parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067b714",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8a2ce",
   "metadata": {},
   "source": [
    "## Regression Kriging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab54ee8",
   "metadata": {},
   "source": [
    "`Predictive variables:` month (MM), day (GG), height (Quota (m s.l.m))\n",
    "<br> <br>\n",
    "`Target variables:` 'tmedia', 'tmax', 'tmin', 'ptot', 'vmedia', 'vraffica', 'settore_prevalente', 'tempo_permanenza',\n",
    "       'durata_calma', 'umedia', 'umin', 'umax', 'rtot', 'hdd_base18', 'hdd_base20', 'cdd_base18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_month_day_to_day_number(year, month, day):\n",
    "    feb = 28\n",
    "    if year in list(range(2000, 2025, 4)):\n",
    "        feb += 1\n",
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_month_day_to_day_number(year, month, day):\n",
    "    feb = 28\n",
    "    if year in list(range(2000, 2025, 4)):\n",
    "        feb += 1\n",
    "        \n",
    "    days_per_month = [31, feb, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    day_of_year = sum(days_per_month[:month - 1]) + day + year\n",
    "    return day_of_year\n",
    "\n",
    "sector_to_degree = {\n",
    "        'Calma di vento': 0,\n",
    "        'N': 1,\n",
    "        'NNE': 2,\n",
    "        'NE': 3,\n",
    "        'ENE': 4,\n",
    "        'E': 5,\n",
    "        'ESE': 6,\n",
    "        'SE': 7,\n",
    "        'SSE': 8,\n",
    "        'S': 9,\n",
    "        'SSW': 10,\n",
    "        'SW': 11,\n",
    "        'WSW': 12,\n",
    "        'W': 13,\n",
    "        'WNW': 14,\n",
    "        'NW': 15,\n",
    "        'NNW': 16\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9b276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(gdf, vars = ['tmedia', 'tmax', 'tmin', 'ptot', 'vmedia', 'vraffica', 'settore_prevalente', 'tempo_permanenza',\n",
    "       'durata_calma', 'umedia', 'umin', 'umax', 'rtot', 'hdd_base18', 'hdd_base20', 'cdd_base18']):\n",
    "    result = dict.fromkeys(vars)\n",
   "    \n",
     "    aux = gdf\n",
     "    aux['settore_prevalente'] = aux.loc[:, 'settore_prevalente'].map(sector_to_degree)\n",
     "    aux['day'] = aux.apply(lambda x: year_month_day_to_day_number(x['YYYY'], x['MM'], x['DD']), axis=1)\n",
     "\n",
     "    for key in result.keys():\n",
     "        foo = aux[['day', 'Quota (m s.l.m.)', key, 'geometry']]\n",
     "        mask = foo[key].dropna().index \n",
     "        foo = foo.loc[mask, :]\n",
     "\n",
     "        result[key] = foo.rename(columns={'Quota (m s.l.m.)': 'height'})\n",
     "\n",
     "    return result"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "6f351461",
    "metadata": {},
    "outputs": [],
    "source": [
     "meteo_per_kriging = DataLoader(meteo_totale)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "c08bfbcb",
    "metadata": {},
    "outputs": [],
    "source": [
     "import pickle\n",
     "\n",
     "with open('data_for_weather_kriging.pkl', 'wb') as f:\n",
     "    pickle.dump(meteo_per_kriging, f)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "de5229cf",
    "metadata": {},
    "outputs": [],
    "source": [
     "with open('data_for_weather_kriging.pkl', 'rb') as f:\n",
     "    loaded_dict = pickle.load(f)\n",
     "\n",
     "loaded_dict.keys()\n"
    ]
   },
   {
    "cell_type": "markdown",
    "id": "4ab35687",
    "metadata": {},
    "source": [
     "---"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "7c5fa168",
    "metadata": {},
    "outputs": [],
    "source": [
     "from sklearn.ensemble import GradientBoostingRegressor\n",
     "from sklearn.linear_model import ElasticNet\n",
     "from sklearn.linear_model import SGDRegressor\n",
     "from sklearn.svm import SVR\n",
     "from sklearn.linear_model import BayesianRidge\n",
     "from catboost import CatBoostRegressor\n",
     "from sklearn.kernel_ridge import KernelRidge\n",
     "from sklearn.linear_model import LinearRegression\n",
     "from xgboost.sklearn import XGBRegressor\n",
     "from lightgbm import LGBMRegressor\n",
     "\n",
     "from sklearn.model_selection import GridSearchCV\n",
     "from pykrige.rk import RegressionKriging"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "d8ea02cf",
    "metadata": {},
    "outputs": [],
    "source": [
     "help(RegressionKriging)"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
    "id": "c65dad31",
    "metadata": {},
    "outputs": [],
    "source": [
     "# Example usage:\n",
     "# Suppose you have your input data in arrays X (with spatial coordinates in columns 0-1)\n",
     "# and y (the target values). Then you can set up a parameter grid and run grid search.\n",
     "\n",
     "# Define the parameter grid for the kriging hyperparameters.\n",
     "param_grid = {\n",
     "    'regression_model': [LinearRegression(), \n",
     "                         GradientBoostingRegressor(), \n",
     "                         ElasticNet(), \n",
     "                         SGDRegressor(), \n",
     "                         SVR(), \n",
     "                         BayesianRidge(), \n",
     "                         CatBoostRegressor(),\n",
     "                         KernelRidge(),\n",
     "                         XGBRegressor(),\n",
     "                         LGBMRegressor()],\n",
     "    'variogram_model': ['spherical', 'exponential', 'gaussian', 'linear', 'power', 'hole-effect'],\n",
     "    'nlags': [6, 10, 15]\n",
     "}\n",
     "\n",
     "# Create the grid search object with 5-fold cross-validation.\n",
     "grid_search = GridSearchCV(RegressionKriging(method='universal'), param_grid, \n",
     "                           scoring='neg_mean_squared_error', \n",
     "                           cv=10, \n",
     "                           verbose=True,\n",
     "                           njobs=-1)\n",
     "\n",
     "# Assuming X and y are defined, run the grid search.\n",
     "# grid_search.fit(X_train, y_train)\n",
     "# To print the best parameters:\n",
     "# print(\"Best parameters:\", grid_search.best_params_)\n",
     "# And to get predictions on a new dataset X_new:\n",
     "# y_pred = grid_search.best_estimator_.predict(X_new)\n"
    ]
   },
   {
    "cell_type": "markdown",
    "id": "7389e6da",
    "metadata": {},
    "source": [
     "After the found of the best model for regression kriging, apply the model to each day for each year"
     "After the found of the best model for regression kriging, apply the model to each day for each year"
    ]
   }
  ],
  "metadata": {
   "kernelspec": {
    "display_name": ".venv",
    "language": "python",
    "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
     "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.10.17"
   }
  },
  "nbformat": 4,
  "nbformat_minor": 5
 }