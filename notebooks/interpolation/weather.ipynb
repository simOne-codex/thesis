{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90836170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(rf'/nfs/home/genovese/thesis-wildfire-genovese/src/')\n",
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "data_folder = '/nfs/home/genovese/thesis-wildfire-genovese/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95c9d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "confini = gpd.read_file('/nfs/home/genovese/thesis-wildfire-genovese/data/clean_data/confini_piemonte/confini_piemonte.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0631ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo = dict()\n",
    "    \n",
    "for a in list(range(2000, 2025)):\n",
    "    meteo[a] = gpd.read_file(f'/nfs/home/genovese/thesis-wildfire-genovese/data/gathering_geojson/weather_forecast/{a}.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e2b65",
   "metadata": {},
   "source": [
    "## Ordinary Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0176233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pykrige.ok import OrdinaryKriging\n",
    "    \n",
    "# gdf = meteo[2000]\n",
    "    \n",
    "# mask = gdf['tmedia'].dropna().index \n",
    "# day = gdf.loc[mask, :][gdf.loc[mask, :].data == '2000-01-03'].to_crs(epsg=4326)\n",
    "    \n",
    "# # 5. Extract lat, lon, and temperature data\n",
    "# lons = day.geometry.x.values\n",
    "# lats = day.geometry.y.values\n",
    "# temps = day['tmedia'].values\n",
    "    \n",
    "# # 6. Interpolate using kriging from LandSklim\n",
    "# result = OrdinaryKriging(lons, lats, temps, verbose=True, variogram_model='gaussian')\n",
    "    \n",
    "# grid_lons = np.linspace(confini.total_bounds[0], confini.total_bounds[2], 1000)\n",
    "# grid_lats = np.linspace(confini.total_bounds[1], confini.total_bounds[3], 1000)\n",
    "   \n",
    "# z, ss = result.execute('grid', grid_lons, grid_lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636b37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "    \n",
    "# plt.pcolormesh(grid_lons, grid_lats, z)\n",
    "# # confini.plot(ax=ax, color='lightgray', alpha=0.5)\n",
    "# plt.scatter(lons, lats, c=temps, edgecolors='k', marker='o', label='Data points')\n",
    "    \n",
    "# plt.colorbar(label='Predicted Value')\n",
    "# plt.title('Kriging Interpolation')\n",
    "# plt.xlabel('X Coordinate')\n",
    "# plt.ylabel('Y Coordinate')\n",
    "# plt.legend(loc='best')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd023fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import mean_squared_error\n",
    "# import itertools\n",
    "    \n",
    "# # Define variogram models for the grid search\n",
    "# variogram_models = {'hole-effect', 'spherical', 'exponential', 'gaussian', 'linear', 'power'}\n",
    "# ranges = [10, 20, 30]\n",
    "# slopes = [0.1, 0.3, 0.5]\n",
    "# sills = [1, 5, 7]\n",
    "# nuggets = [0, 2, 5]\n",
    "# scales = [1,3,5]\n",
    "# exponent = [1,2,3]\n",
    "    \n",
    "    \n",
    "# # Grid search to find the best variogram parameters\n",
    "# best_model = None\n",
    "# best_rmse = float('inf')\n",
    "# best_params = None\n",
    "    \n",
    "# for var_model, slope_val, range_val, sill_val, nugget_val, scale_val, exponent_val in list(itertools.product(variogram_models, ranges, slopes, sills, nuggets\n",
    "# , scales, exponent)):\n",
    "#     # Create an OrdinaryKriging object\n",
    "#     OK = OrdinaryKriging(lons, lats, temps, variogram_model=var_model, \n",
    "#                                          variogram_parameters={\n",
    "#                                                  'slope': slope_val, \n",
    "#                                                  'range': range_val, \n",
    "#                                                  'sill': sill_val, \n",
    "#                                                  'nugget': nugget_val,\n",
    "#                                                  'scale': scale_val,\n",
    "#                                                  'exponent': exponent_val},\n",
    "#                                          verbose=False, enable_plotting=False)\n",
    "                    \n",
    "#     z_pred, ss = result.execute('points', lons, lats)\n",
    "    \n",
    "#     rmse = np.sqrt(mean_squared_error(temps, z_pred.flatten()))\n",
    "                    \n",
    "#     # print(f\\Model: {var_model}, Range: {range_val}, Sill: {sill_val}, Nugget: {nugget_val}, RMSE: {rmse}\\)\n",
    "    \n",
    "#     # Update best model if current RMSE is better\n",
    "#     if rmse < best_rmse:\n",
    "#         best_rmse = rmse\n",
    "#         best_model = var_model\n",
    "#         best_params = (range_val, sill_val, nugget_val)\n",
    "    \n",
    "#     # Output the best model and parameters\n",
    "# print('Best Model:', best_model)\n",
    "# print('Best Parameters:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c4bfd",
   "metadata": {},
   "source": [
    "## Regression Kriging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619949f0",
   "metadata": {},
   "source": [
    "`Predictive variables:` day (GG + MM), height (Quota (m s.l.m))\n",
    "<br> <br>\n",
    "`Target variables:` 'tmedia', 'tmax', 'tmin', 'ptot', 'vmedia', 'vraffica', 'settore_prevalente', 'tempo_permanenza',\n",
    "           'durata_calma', 'umedia', 'umin', 'umax', 'rtot', 'hdd_base18', 'hdd_base20', 'cdd_base18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4546b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_day_to_day_number(year, month, day):\n",
    "    feb = 28\n",
    "    if year in list(range(2000, 2025, 4)):\n",
    "        feb += 1\n",
    "            \n",
    "    days_per_month = [31, feb, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    day_of_year = sum(days_per_month[:month - 1]) + day\n",
    "    return day_of_year\n",
    "    \n",
    "sector_to_degree = {\n",
    "            'Calma di vento': 0,\n",
    "            'N': 1,\n",
    "            'NNE': 2,\n",
    "            'NE': 3,\n",
    "            'ENE': 4,\n",
    "            'E': 5,\n",
    "            'ESE': 6,\n",
    "            'SE': 7,\n",
    "            'SSE': 8,\n",
    "            'S': 9,\n",
    "            'SSW': 10,\n",
    "            'SW': 11,\n",
    "            'WSW': 12,\n",
    "            'W': 13,\n",
    "            'WNW': 14,\n",
    "            'NW': 15,\n",
    "            'NNW': 16\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137488ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataLoader(gdf, vars = ['tmedia', 'tmax', 'tmin', 'ptot', 'vmedia', 'vraffica', 'settore_prevalente', 'tempo_permanenza',\n",
    "           'durata_calma', 'umedia', 'umin', 'umax', 'rtot', 'hdd_base18', 'hdd_base20', 'cdd_base18']):\n",
    "        result = dict.fromkeys(vars)\n",
    "       \n",
    "        aux = gdf\n",
    "        aux['settore_prevalente'] = aux.loc[:, 'settore_prevalente'].map(sector_to_degree)\n",
    "        aux['day'] = aux.apply(lambda x: month_day_to_day_number(x['YYYY'], x['MM'], x['DD']), axis=1)\n",
    "     \n",
    "        for key in result.keys():\n",
    "            foo = aux[['day', 'Quota (m s.l.m.)', key, 'geometry']]\n",
    "            mask = foo[key].dropna().index \n",
    "            foo = foo.loc[mask, :]\n",
    "     \n",
    "            result[key] = foo.rename(columns={'Quota (m s.l.m.)': 'height'})\n",
    "     \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b89ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteo_per_kriging = dict()\n",
    "for a, gdf in meteo.items():\n",
    "    meteo_per_kriging[a] = DataLoader(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b12f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('/nfs/home/genovese/thesis-wildfire-genovese/data/data_loader_for_kriging/data_for_weather_kriging.pkl', 'wb') as f:\n",
    "     pickle.dump(meteo_per_kriging, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f6e5ff",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f077b1d",
   "metadata": {},
   "source": [
    "#### Ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c43108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from shapely.geometry import Point\n",
    "\n",
    "# gdf = altimetria.to_crs(epsg=4623)\n",
    "\n",
    "# minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "# # 2. Generate a grid of points\n",
    "# # Set the step size (spacing between grid points)\n",
    "# step = 0.01  # Change this to the desired resolution\n",
    "\n",
    "# # Create the x and y coordinates of the grid\n",
    "# x_coords = np.arange(minx, maxx, step)\n",
    "# y_coords = np.arange(miny, maxy, step)\n",
    "\n",
    "# # Generate a meshgrid of points (all combinations of x and y)\n",
    "# grid_points = np.array(np.meshgrid(x_coords, y_coords)).T.reshape(-1, 2)\n",
    "\n",
    "# # 3. Create Point objects and check if they are inside the polygons\n",
    "# points = [Point(x, y) for x, y in grid_points]\n",
    "\n",
    "# points_within_polygons = [point for point in tqdm(points) if gdf.contains(point).any()]\n",
    "\n",
    "# def get_polygon_value(gdf, point):\n",
    "#     for idx, polygon in gdf.iterrows():\n",
    "#         if polygon['geometry'].contains(point):\n",
    "#             return polygon['MEDIANA']\n",
    "#     return None\n",
    "\n",
    "# # Apply the function to all points\n",
    "# values = [get_polygon_value(gdf, point) for point in tqdm(points_within_polygons)]\n",
    "\n",
    "# # 5. Create a GeoDataFrame with points and associated polygon values\n",
    "# points_gdf = gpd.GeoDataFrame(\n",
    "#     geometry=points_within_polygons,\n",
    "#     data={'polygon_value': values},\n",
    "#     crs=gdf.crs\n",
    "# )\n",
    "\n",
    "# points_gdf.to_file('/nfs/home/genovese/thesis-wildfire-genovese/data/gathering_geojson/altimetric_grid.geojson')\n",
    "\n",
    "# # Show the first few points\n",
    "# print(points_gdf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601bd888",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe37627",
   "metadata": {},
   "source": [
    "### Set points for aimed kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77b43de",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = separate_date(gpd.read_file('/nfs/home/genovese/thesis-wildfire-genovese/data/nicola/piedmont_2012_2024_fa.geojson'), 'initialdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_day_to_day_number(year, month, day):\n",
    "    feb = 28\n",
    "    if year in list(range(2000, 2025, 4)):\n",
    "        feb += 1\n",
    "            \n",
    "    days_per_month = [31, feb, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    day_of_year = sum(days_per_month[:month - 1]) + day\n",
    "    return day_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target['day_of_year'] = target.apply(lambda x: month_day_to_day_number(x['YYYY'], x['MM'], x['DD']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad428f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "altimetria = gpd.read_file('/nfs/home/genovese/thesis-wildfire-genovese/data/gathering_geojson/altimetria_per_circoscrizione.geojson').to_crs(target.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbedf5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "target['ignition_point'] = [Point(x, y) for x, y in tqdm(zip(target.point_x, target.point_y))]\n",
    "\n",
    "def get_polygon_value(gdf, point, value):\n",
    "    for idx, polygon in gdf.iterrows():\n",
    "        if polygon['geometry'].contains(point):\n",
    "            return polygon[value]\n",
    "    return None\n",
    "\n",
    "# Apply the function to all points\n",
    "values = [get_polygon_value(altimetria, point, 'MEDIANA') for point in tqdm(target['ignition_point'])]\n",
    "\n",
    "# 5. Create a GeoDataFrame with points and associated polygon values\n",
    "points_gdf = gpd.GeoDataFrame(\n",
    "    geometry='ignition_point',\n",
    "    data={'height': values},\n",
    "    crs=altimetria.crs\n",
    ")\n",
    "\n",
    "for_kriging = gpd.GeoDataFrame(target[['day_of_year', 'ignition_point']], geometry='ignition_point'\n",
    "                               ).merge(points_gdf, on='geometry', how='inner')\n",
    "\n",
    "for_kriging.to_file('/nfs/home/genovese/thesis-wildfire-genovese/data/data_loader_for_kriging/kriging_weatehr_grid.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f91f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be199409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('/nfs/home/genovese/thesis-wildfire-genovese/data/data_loader_for_kriging/data_for_weather_kriging.pkl', 'rb') as f:\n",
    "     loaded_dict = pickle.load(f)\n",
    "     \n",
    "print(list(loaded_dict.keys()))\n",
    "\n",
    "ignitions = gpd.read_file('/nfs/home/genovese/thesis-wildfire-genovese/data/data_loader_for_kriging/kriging_weatehr_grid.geojson'\n",
    "                       ).rename(columns={'day_of_year': 'day'}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from pykrige.rk import RegressionKriging\n",
    "\n",
    "def rk_train_pred(X_train, X_pred, target_col):\n",
    "    RK = RegressionKriging(regression_model = GradientBoostingRegressor(), method='universal', variogram_model = 'spherical', verbose=1)\n",
    "       \n",
    "    RK.fit(p = X_train[['height']], x = np.transpose(np.array([X_train.geometry.x, X_train.geometry.y])), y = X_train[target_col])\n",
    "       \n",
    "    y_pred = RK.predict(p = X_pred[['height']], x = np.transpose(np.array([X_pred.geometry.x, X_pred.geometry.y])))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "\n",
    "def yearly_forecast(loaded_dict, target, year):\n",
    "    \n",
    "    centraline = loaded_dict[year]\n",
    "    tt = target[target['YYYY'] == year]\n",
    "\n",
    "    forecasts = tt.copy()\n",
    "    \n",
    "    for var, gdf in tqdm(centraline.items(), desc=f'Running year: {year}'):\n",
    "\n",
    "        parameter_forecast = gpd.GeoDataFrame()\n",
    "\n",
    "        for day, X_pred in tqdm(tt.groupby('day'), desc=f'Running variable: {var}'):\n",
    "            aux = X_pred.copy()\n",
    "            X_train = gdf[gdf.day == day]\n",
    "            y_pred = rk_train_pred(X_train, X_pred, var)\n",
    "            aux = pd.concat([aux, y_pred], axis=1)\n",
    "            parameter_forecast = pd.concat([parameter_forecast, aux], axis=0, ignore_index=True)\n",
    "\n",
    "        forecasts.merge(parameter_forecast, on='geometry', how='inner')\n",
    "\n",
    "    return forecasts\n",
    "\n",
    "\n",
    "\n",
    "weather_forecast = dict()\n",
    "\n",
    "for year in tqdm(ignitions.YYYY.unique()):\n",
    "    weather_forecast[year] = yearly_forecast(loaded_dict, ignitions, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c19be3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a93d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(rf\"/nfs/home/genovese/thesis-wildfire-genovese/src\")\n",
    "from importlib import reload\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "import weather_forecast_utils\n",
    "reload(weather_forecast_utils)\n",
    "from weather_forecast_utils import *\n",
    "data_folder = \"/nfs/home/genovese/thesis-wildfire-genovese/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559172e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "with open('/nfs/home/genovese/thesis-wildfire-genovese/data/data_loader_for_kriging/data_for_weather_kriging.pkl', 'rb') as f:\n",
    "     loaded_dict = pickle.load(f)\n",
    "\n",
    "ignitions = gpd.read_file('/nfs/home/genovese/thesis-wildfire-genovese/data/data_loader_for_kriging/kriging_weather_grid.geojson'\n",
    "                       ).rename(columns={'day_of_year': 'day'}) \n",
    "\n",
    "# save_clean_data(yearly_forecast(loaded_dict, ignitions, 2016), str(2016), '/nfs/home/genovese/thesis-wildfire-genovese/data/output_weather_kriging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed247999",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_forecast(loaded_dict, ignitions, 2016)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
